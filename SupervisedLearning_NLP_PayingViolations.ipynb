{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SupervisedLearning_NLP-PayingViolations.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0TPovETyyYAM",
        "ja3GETkqzGFY",
        "fYeGvzClL8df",
        "sMOgaf6LVGz4",
        "QBbCTxSnMDYt",
        "awQiMg3wMHPL",
        "AALfkDGOMNMf",
        "nbqK9JmeMOxz",
        "oP7lA0zrMV6I",
        "SCSCaZcZMXcr",
        "CxDKG3n6MbuZ",
        "AiWR-sG5MdYj",
        "wCkdaBPZMfZN",
        "x8oj4BawMheS",
        "W5eji-t3Mmj2",
        "Y5RHdtt-XrOS",
        "_NSwjiGbMobM",
        "_Vao04POMptt",
        "MbX1yCyihA4_",
        "Qlwy_ng_NWmM",
        "cPlSbpeLhKOA",
        "koaueD8RY3iU",
        "mGQ67wy037GZ",
        "SgDvQSSa9adg",
        "WInbCQfa9eyd",
        "Q1x4ByHy_WPY",
        "reFPu9_muAQb",
        "VOlfaBSiBxIk",
        "AltwuX7wB4b_",
        "dvoGO5ufZ7sy",
        "EKDs7xoOucg0",
        "L2YZz7DlC5D4",
        "_U3_96jEC9_V",
        "ceyJnucVu6Dy",
        "tZY5E__-4G-R",
        "iI-8j4iGDVyq",
        "Fnseg3mAvbEY",
        "iDDVa_Zo-wO3",
        "2chBbpUAkY30",
        "LXoK-4xhDJ4O"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO1pKY81+Ssh9mCmhv//IAH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Starsa/thinkful_challenges/blob/master/SupervisedLearning_NLP_PayingViolations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWi_W1wf-2cO"
      },
      "source": [
        "##### New York City- Department of Buildings\n",
        "<h1>DOB ECB Fines- a brief Analysis</h1>\n",
        "<h3>Are DOB Violations precautionary or just a headache?</h3>\n",
        "<p>The Department of Buildings (DOB) in New York City regulates City Construction Codes, Zoning, and  Dwelling Laws for over one million construction sites and buildings in New York City. Their aim is to enforce compliance to promote safety for workers and the public.<p> \n",
        "\n",
        "<p>With their annual reviews and site inspections Violations are issued across the city for a range of differnt infractions.</p>\n",
        "\n",
        "<p> Although a significant amount of violations end with a $0 amount of penalty imposed, I would like to build a model that predicts whether or not a penalty will be paid. This information could be helpful for the NYC DOB in issuing payment reminders, which at present are at best non-existant.</p>\n",
        "\n",
        "The dataset is from the [New York City Open Data source](https://data.cityofnewyork.us/Housing-Development/DOB-ECB-Violations/6bgk-3dad) api which is updated daily and pertains specifically to the DOB ECB (Enviornmental Control Board) violations. The data has approx. 1.5 million datapoints dating back to before 1920.\n",
        "___\n",
        "#Outline:\n",
        "* GOAL: identify resolution of violations, using NLP  analysis of a violation description and/or violation type.\n",
        "\n",
        "* My process will include:\n",
        "  * Inital Exploratory Analysis of the data: Understand features and create target, perform data cleaning, and feature engineering.\n",
        "  * NLP Feature Extraction: Using NLP tools to extract features by \n",
        "  * Supervised Learning: using classification techniques to train models and compare results on unseen data.\n",
        "  * Model Tuning: Optimize any relevant hyperparameters or features for at least 3 models using GridSearchCV\n",
        "\n",
        "* The questions I'm hoping to explore are:\n",
        "  * Can we effectively train a model to classify and predict if a violation gets paid using predominatley text-based comments?\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpHv_0WN1vX_"
      },
      "source": [
        "___\n",
        "## Load data and inspect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4ZyjDaeZAxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36bd320d-95d3-447a-8be5-0aadb6a88e09"
      },
      "source": [
        "#had some issues loading some libaries \n",
        "! pip show spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: spacy\n",
            "Version: 2.2.4\n",
            "Summary: Industrial-strength Natural Language Processing (NLP) in Python\n",
            "Home-page: https://spacy.io\n",
            "Author: Explosion\n",
            "Author-email: contact@explosion.ai\n",
            "License: MIT\n",
            "Location: /usr/local/lib/python3.7/dist-packages\n",
            "Requires: preshed, blis, wasabi, srsly, numpy, requests, murmurhash, catalogue, tqdm, thinc, cymem, plac, setuptools\n",
            "Required-by: fastai, en-core-web-sm\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwUHsT5Txj6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a906838-78da-4f2d-d203-e0e01ef56919"
      },
      "source": [
        "#install package according to API info for NYC open data\n",
        "!pip install sodapy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sodapy\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/74/95fb7d45bbe7f1de43caac45d7dd4807ef1e15881564a00eef489a3bb5c6/sodapy-2.1.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from sodapy) (2.23.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->sodapy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->sodapy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->sodapy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->sodapy) (2020.12.5)\n",
            "Installing collected packages: sodapy\n",
            "Successfully installed sodapy-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eqpEjk-KrSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975ef6fc-b887-47f9-c102-d6783d813824"
      },
      "source": [
        "#split from other imports as per issues loading.\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-o_ODyDKz2w"
      },
      "source": [
        "# Importing Packages\n",
        "from sodapy import Socrata\n",
        "\n",
        "%matplotlib inline\n",
        "import sys, os, random\n",
        "import nltk, re\n",
        "import time\n",
        "import tweepy \n",
        "import scipy\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from textblob import TextBlob \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# preprocessing and feature extraction\n",
        "# bag of words scipy.sparse()\n",
        "from scipy.stats.mstats import winsorize\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "\n",
        "# Training the classifier\n",
        "from sklearn.pipeline import Pipeline # classifier to make the vectorizer => transformer => classifier easier \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Classifiers for building models\n",
        "import statsmodels.api as sm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Evaluation \n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from statsmodels.tools.eval_measures import mse, rmse"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0VKXZoVv87o"
      },
      "source": [
        "# in place of application token, and no username or password:\n",
        "client = Socrata(\"data.cityofnewyork.us\", \"yhtcrJSTvLPhjqPpNHGf1tTyN\", username=\"starsasmile@gmail.com\", password=\"Tosca2010\")\n",
        "\n",
        "# Example authenticated client (needed for non-public datasets):\n",
        "# client = Socrata(data.cityofnewyork.us,\n",
        "#                  MyAppToken,\n",
        "#                  userame=\"user@example.com\",\n",
        "#                  password=\"AFakePassword\")\n",
        "\n",
        "# First 2000 results, returned as JSON from API / converted to Python list of\n",
        "# dictionaries by sodapy.\n",
        "results = client.get(\"6bgk-3dad\", limit= 1500000)\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "results_df = pd.DataFrame.from_records(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeqr7mC2ylVn"
      },
      "source": [
        "results_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3I7wyP2vyp0m"
      },
      "source": [
        "results_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGXL7XNWzrF3"
      },
      "source": [
        "#make a copy of the dataset to use\n",
        "dob_df = results_df.copy(deep=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJgKj1nEzx-M"
      },
      "source": [
        "#review data missing values and statistics\n",
        "print(dob_df.info())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRUwrTuez0LE"
      },
      "source": [
        "#rename columns for ease of use\n",
        "dob_df.columns = dob_df.columns.str.strip()\n",
        "dob_df = dob_df.rename(columns={'penality_imposed':'penalty_imposed'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghQdbM442zh5"
      },
      "source": [
        "#convert known integers to numeric\n",
        "dob_df['penalty_imposed']= pd.to_numeric(dob_df['penalty_imposed'], errors=\"coerce\")\n",
        "dob_df['amount_paid']= pd.to_numeric(dob_df['amount_paid'], errors=\"coerce\")\n",
        "dob_df['balance_due']= pd.to_numeric(dob_df['balance_due'], errors=\"coerce\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wv6Yc6l24__N"
      },
      "source": [
        "#check dtypes\n",
        "dob_df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-gRMwnm3LIl"
      },
      "source": [
        "#look at percentage missing and drop columns with more than 40% missing data\n",
        "#review missing data and percentages\n",
        "total_missing = dob_df.isnull().sum().sort_values(ascending=False)\n",
        "percent_missing = (dob_df.isnull().sum()/dob_df.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total_missing, percent_missing], axis=1, keys=['Total', 'Percent'])\n",
        "missing_data.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0ulUtEu5gwS"
      },
      "source": [
        "#drop columns with over 40% missing data and columns least likely to affect our data\n",
        "dob_df = dob_df.drop(['infraction_code3','section_law_description3', 'infraction_code4','section_law_description4',\n",
        "                'infraction_code5','section_law_description5', 'infraction_code6','section_law_description6', \n",
        "                'infraction_code7', 'section_law_description7', 'infraction_code8', 'section_law_description8', \n",
        "                'infraction_code9','section_law_description9', 'infraction_code10', 'section_law_description10', \n",
        "                'infraction_code2', 'section_law_description2'], axis=1)\n",
        "#we will keep aggravated for now and see if we can change it to a discrete variable.\n",
        "\n",
        "#reset the index for good practice when dropping\n",
        "dob_df = dob_df.reset_index(drop=True)\n",
        "#get the shape of our new dataset\n",
        "dob_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TviiqMbE5_sv"
      },
      "source": [
        "#review variables for categorical variables\n",
        "dob_df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TPovETyyYAM"
      },
      "source": [
        "___\n",
        "## Drop Features\n",
        "Now we will drop some features that will not be important to this model. It would be interesting to create a different experiment in the future using some of these features in attempting to find bias from inspector comments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39IS93KqyStN"
      },
      "source": [
        "dob_df = dob_df.drop(columns=[\"isn_dob_bis_extract\",\"ecb_violation_number\", \"bin\", \"block\", \"lot\", \n",
        "                              \"served_date\", \"issue_date\", \"respondent_name\", \"respondent_house_number\", \n",
        "                              \"respondent_street\", \"respondent_zip\", \"respondent_city\", \"infraction_code1\",\n",
        "                              \"section_law_description1\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja3GETkqzGFY"
      },
      "source": [
        "___\n",
        "## EDA and Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYeGvzClL8df"
      },
      "source": [
        "### ecb_violation_status \n",
        "Indicates whether or not the violation has been corrected. This is the status of the violation with DOB, not the status of the hearing with OATH.\n",
        "\n",
        "Expected values = \n",
        "* ACTIVE - still needs to be addressed\n",
        "* RESOLVE - the issue was either fixed with DOB or dismissed by OATH\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1om9JGpNMOT"
      },
      "source": [
        "dob_df.ecb_violation_status.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtUZf3WzXV6Q"
      },
      "source": [
        "dob_df.ecb_violation_status.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7BtuuGGXfwV"
      },
      "source": [
        "dob_df.loc[dob_df['ecb_violation_status'] ==\"Unknown\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSiuHSlmXZQi"
      },
      "source": [
        "#get rid of one unknown row it does not provide much information\n",
        "dob_df = dob_df.loc[dob_df['ecb_violation_status']!= \"Unknown\"]\n",
        "\n",
        "#reset the index for good practice when dropping\n",
        "dob_df = dob_df.reset_index(drop=True)\n",
        "#get the shape of our new dataset\n",
        "dob_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qj7Xgcp-YSO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMOgaf6LVGz4"
      },
      "source": [
        "#### Violation Status (an engineered variable)\n",
        "We will convert to numeric:\n",
        "  * Resolved = 1\n",
        "  * Active = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-MvwrD1VEl_"
      },
      "source": [
        "#Here we will change Resolved to 1, Active to active and deal with our 'unknown' variable.\n",
        "dob_df['violation_status']= np.where((dob_df['ecb_violation_status']== \"RESOLVE\"), 1, 0)\n",
        "dob_df.violation_status.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBbCTxSnMDYt"
      },
      "source": [
        "### dob_violation_number\n",
        "When an ECB violation is issued, Department of Buildings also issues a violation. This is the unique identifier for the violation issued by the Department of Buildings. See the DOB Violations dataset for more information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyORd1QZNR1u"
      },
      "source": [
        "dob_df.dob_violation_number.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9W-7cPjNc5a"
      },
      "source": [
        "#check duplicates of top \n",
        "#there should be no duplicates this is a unique identifier\n",
        "dob_df.loc[dob_df['dob_violation_number'] == \"112808NRF\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZSGTAHzPGva"
      },
      "source": [
        "#this is not the only duplicates number.\n",
        "#will drop duplicates and then drop column to eliminate errors\n",
        "dob_df = dob_df.drop_duplicates(subset= 'dob_violation_number' )\n",
        "dob_df = dob_df.drop(\"dob_violation_number\", axis=1)\n",
        "\n",
        "#reset the index for good practice when dropping\n",
        "dob_df = dob_df.reset_index(drop=True)\n",
        "#get the shape of our new dataset\n",
        "dob_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy1EBuQOzrX1"
      },
      "source": [
        "We don't need duplicate data. There are clearly errors here as it is allegedly a unique identifier. We dropped the duplicates and then proceeded to drop this variable from our data_set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awQiMg3wMHPL"
      },
      "source": [
        "### boro\n",
        "A number to indicate the NYC borough where the violation was issued.\n",
        "\n",
        "Expected values: \n",
        "* 1 = Manhattan\n",
        "* 2 = Bronx\n",
        "* 3 = Brooklyn\n",
        "* 4 = Queens\n",
        "* 5 = Staten Island"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxAP0LXBbZsR"
      },
      "source": [
        "dob_df.boro.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh4qFVdOhKjJ"
      },
      "source": [
        "dob_df.loc[dob_df['boro']==\"6\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwY7b_G2hQLB"
      },
      "source": [
        "dob_df.loc[dob_df['boro']==\"3012920\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZMKLV9oij7k"
      },
      "source": [
        "dob_df['boro'] = dob_df['boro'].replace(\"3012920\", \"6\")\n",
        "dob_df = dob_df.loc[dob_df[\"boro\"]!= \"6\"]\n",
        "\n",
        "# set category to numeric for model prep later\n",
        "dob_df['boro'] = pd.to_numeric(dob_df['boro'], errors=\"coerce\")\n",
        "dob_df.boro.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDtrk30Z2JEi"
      },
      "source": [
        "#reset the index for good practice when dropping\n",
        "dob_df = dob_df.reset_index(drop=True)\n",
        "#get the shape of our new dataset\n",
        "dob_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz16NEUMnBt-"
      },
      "source": [
        "dob_df.boro.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qrph2jIP5_I8"
      },
      "source": [
        "ax = sns.stripplot(x=\"boro\", y=\"penalty_imposed\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AALfkDGOMNMf"
      },
      "source": [
        "### hearing_date\n",
        "Date of the latest scheduled hearing for the respondent named on the violation to admit to it or contest the violation.\n",
        "\n",
        "* YYYYMMDD format\n",
        "* This date may change if, for example, the hearing is postponed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LtCGzt5nhrn"
      },
      "source": [
        "dob_df.hearing_date.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvSVPsY75wWw"
      },
      "source": [
        "#clean up date format for hearing date\n",
        "dob_df['hearing_date']=pd.to_datetime(dob_df['hearing_date'], format='%Y%m%d')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xTGG3N3AJmF"
      },
      "source": [
        "dob_df.hearing_date.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNZ5ci2NAWHT"
      },
      "source": [
        "plt.hist(dob_df.hearing_date)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9xiCcvy0y5b"
      },
      "source": [
        "dob_df.loc[(dob_df['hearing_date']> \"20210228\") & (dob_df['ecb_violation_status']== \"RESOLVE\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXSIopxy3bWk"
      },
      "source": [
        "Will keep to see if we can engineer any variables for it. It would be also interesting to compare this with dollar amounts in a time series analysis. Although there are some dates in the future, this is due to hearing dates that need more time and it was probably decided in a seperate appearance. If the violation_status is "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbqK9JmeMOxz"
      },
      "source": [
        "### hearing_time\n",
        "Time of the scheduled hearing for the respondent named on the violation to admit to it or contest the violation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcHLh4uBAws5"
      },
      "source": [
        "dob_df.hearing_time.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq1HXlRuBcGc"
      },
      "source": [
        "dob_df.hearing_time = pd.to_numeric(dob_df.hearing_time, errors=\"coerce\")\n",
        "pd.isnull(dob_df.hearing_time).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jTPXauF3f3A"
      },
      "source": [
        "dob_df.hearing_time.value_counts().head(60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW-xTX2MCOtd"
      },
      "source": [
        "plt.hist(dob_df.hearing_time)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npVtGcOQ7pnO"
      },
      "source": [
        "On closer inspection the times vary more than we'd like. We will categorize them into morning or afternoon \n",
        "  * morning =1\n",
        "  * afternoon = 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VK63sKs3A5l"
      },
      "source": [
        "dob_df['hearing_time_morning']= np.where((dob_df['hearing_time']<=1200), 1, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUC1Ys2F8vhU"
      },
      "source": [
        "ax = sns.barplot(x=\"hearing_time_morning\", y=\"penalty_imposed\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LNJU2ky3pAA"
      },
      "source": [
        "Interesting. The penalty amounts are higher for afternoon hearing dates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oP7lA0zrMV6I"
      },
      "source": [
        "### severity\n",
        "Indicated Violation Severity.\n",
        "Expected values: \n",
        "* Hazardous\n",
        "* Non-Hazardous\n",
        "* Unknown"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R2kaF1_ZVrB"
      },
      "source": [
        "print(dob_df.severity.unique())\n",
        "print(dob_df.severity.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COQ0xb2O4uHr"
      },
      "source": [
        "This will be easy to feature engineer. Will keep to see if it adds value to model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuiI-ddtXGW3"
      },
      "source": [
        "#combine unkown and non-hazerdous then convert to numeric\n",
        "dob_df['severity'] = dob_df['severity'].replace((\"Unknown\", \"Non_Hazardous\"), \"Unknown/Non-Hazerdous\")\n",
        "dob_df['severity_cat'] = np.where((dob_df['severity']== \"Hazardous\"), 1,0)\n",
        "dob_df.severity.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCSCaZcZMXcr"
      },
      "source": [
        "### violation_type\n",
        "Violations are grouped into types based on their infraction code.\n",
        "Expected values:\n",
        "* Administrative\n",
        "* Boilers\n",
        "* Construction\n",
        "* Cranes and Derricks\n",
        "* Elevators\n",
        "* HPD\n",
        "* Local Law\n",
        "* Padlock\n",
        "* Plumbing\n",
        "* Public Assembly\n",
        "* Quality of Life\n",
        "* Signs\n",
        "* Site Safety\n",
        "* Unknown\n",
        "* Zoning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XnVtyg7aC41"
      },
      "source": [
        "print(dob_df.violation_type.unique())\n",
        "print(dob_df.violation_type.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwvG-ygN427f"
      },
      "source": [
        "This may be a good column to apply NLP techniques to. No missing values. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxDKG3n6MbuZ"
      },
      "source": [
        "### violation_description\n",
        "Comments from the ECB inspector who issued the violation.\n",
        "\n",
        "\n",
        "\n",
        "> *Some Elevator violations issued during a certain timeframe used alphanumeric codes in the description to further describe the violating condition. See the Elevator Codes sheet within this data dictionary document for the code list, which is also printed on the ECB Summons itself.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhU7mkKSNM6b"
      },
      "source": [
        "#replace nan with unknown to run nlp techniques \n",
        "dob_df.violation_description = dob_df.violation_description.replace(np.nan, 'Unknown').str.strip().str.lower().str.replace('.', '')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiWR-sG5MdYj"
      },
      "source": [
        "### penalty_imposed\n",
        "Amount of the penalty imposed by OATH after adjudication(USD).\n",
        "\n",
        "*We will use this as our target variable.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkDrI5Wwg3MU"
      },
      "source": [
        "dob_df.penalty_imposed.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tv92vqQRWh0"
      },
      "source": [
        "sns.set_style('whitegrid')\n",
        "ax = sns.distplot(dob_df.penalty_imposed, bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoNLsWw86pJS"
      },
      "source": [
        "from scipy.stats import boxcox\n",
        "#check how much information we retain then perform box_cox transformation\n",
        "dob_2= dob_df.loc[dob_df['penalty_imposed'] > 0]\n",
        "\n",
        "penalty_imposed,_ = boxcox(dob_2['penalty_imposed'])\n",
        "\n",
        "print(dob_2.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9h0DSsW7Gj7"
      },
      "source": [
        "sns.set_style('whitegrid')\n",
        "ax = sns.distplot(penalty_imposed, bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCkdaBPZMfZN"
      },
      "source": [
        "### amount_paid\n",
        "Amount that was paid toward the penalty (USD)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLieWmQwilYa"
      },
      "source": [
        "dob_df.amount_paid.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpitXfa4SH5T"
      },
      "source": [
        "sns.set_style('whitegrid')\n",
        "ax = sns.distplot(dob_df.amount_paid, bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHDJsT-_NP-J"
      },
      "source": [
        "ax = sns.barplot(y=\"violation_type\", x=\"amount_paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8oj4BawMheS"
      },
      "source": [
        "### balance_due\n",
        "Amount that is left to be paid toward the penalty."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od5GyWPIin2F"
      },
      "source": [
        "dob_df.balance_due.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdu4SAznSUP3"
      },
      "source": [
        "sns.set_style('whitegrid')\n",
        "ax = sns.distplot(dob_df.balance_due, bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5eji-t3Mmj2"
      },
      "source": [
        "### aggravated_level\n",
        "This indicates if the RESPONDENT_NAME has a pattern of ECB violations or that there was a fatality, serious injury or risk thereof at the place of occurrence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZEhJ6WS5y6j"
      },
      "source": [
        "dob_df.aggravated_level.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekjmlRAyK9sI"
      },
      "source": [
        "dob_df.aggravated_level.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8heNuuakXq0"
      },
      "source": [
        "#replace missing or nan values with 'NO'\n",
        "dob_df['aggravated_level'] = dob_df['aggravated_level'].replace(np.nan, 'NO')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiCyHFoRkh2L"
      },
      "source": [
        "dob_df.aggravated_level.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRfzuAax8cAE"
      },
      "source": [
        "After dropping the null values, this would be easy to convert to a numeric feature. Will keep this variable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5RHdtt-XrOS"
      },
      "source": [
        "### aggravated level"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yC1nYIoXz-k"
      },
      "source": [
        "dob_df.aggravated_level.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smVDErX1X5aO"
      },
      "source": [
        "#combine all aggravate offenses into one variable and then convert to numeric\n",
        "dob_df[\"aggravated_level\"] = dob_df[\"aggravated_level\"].replace((\n",
        "    \"AGGRAVATED OFFENSE LEVEL 1\", \"MULTIPLE OFFENSE\", \"AGGRAVATED OFFENSE LEVEL 2\" ), \"AGGRAVATED\")\n",
        "dob_df[\"aggravated_level_cat\"] = np.where((dob_df[\"aggravated_level\"]==\"AGGRAVATED\"), 1,0 )\n",
        "dob_df.aggravated_level.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NSwjiGbMobM"
      },
      "source": [
        "### hearing_status\n",
        "Status of the hearing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvdZOvEFkKtr"
      },
      "source": [
        "dob_df.hearing_status.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zh9hEcvfkQbd"
      },
      "source": [
        "dob_df.hearing_status.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrANIJWsk_Mk"
      },
      "source": [
        "dob_df.hearing_status.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4WaA_aulG0i"
      },
      "source": [
        "dob_df['hearing_status'] = dob_df['hearing_status'].replace(np.nan, 'unknown')\n",
        "dob_df = dob_df.loc[dob_df['hearing_status']!= 'unknown']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ey58E1vkl8eD"
      },
      "source": [
        "#reset the index for good practice when dropping\n",
        "dob_df = dob_df.reset_index(drop=True)\n",
        "#get the shape of our new dataset\n",
        "dob_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47Q2mQAPHjPh"
      },
      "source": [
        "dob_df.loc[dob_df[\"hearing_status\"]==\"PENDING\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MhTDEe58sUv"
      },
      "source": [
        "Will convert these to numeric values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdgvVbZ2YsYo"
      },
      "source": [
        "dob_df.hearing_status.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0XHzddgY25S"
      },
      "source": [
        "#combine in violation and dismissed or cured then convert to numeric\n",
        "dob_df[\"hearing_status\"] = dob_df[\"hearing_status\"].replace((\n",
        "    \"CURED/IN-VIO\", \"STIPULATION/IN-VIO\", \"POP/IN-VIO\",\"ADMIT/IN-VIO\"), \"IN VIOLATION\").replace((\n",
        "    \"DISMISSED\", \"WRITTEN OFF\"), \"DISMISSED/WRITTEN OFF\")\n",
        "dob_df.hearing_status.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXnTJXcvbam0"
      },
      "source": [
        "#use label encoder to get caategory numbers for model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "lbe = LabelEncoder()\n",
        "dob_df[\"hearing_status_cat\"] = lbe.fit_transform(dob_df[\"hearing_status\"])\n",
        "dob_df.hearing_status_cat.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Vao04POMptt"
      },
      "source": [
        "### certification status\n",
        "Indicates whether respondent/owner has certified the violation as corrected with DOB."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCi-m6aYksKN"
      },
      "source": [
        "dob_df.certification_status.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXKeQNUwkw9b"
      },
      "source": [
        "dob_df.certification_status.unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4QCg99Dmcvh"
      },
      "source": [
        "#added 'N/A Dismissed to Dismissed\n",
        "dob_df['certification_status'] = dob_df['certification_status'].replace('N/A - DISMISSED', 'DISMISSED')\n",
        "#nan values become 'No Compliance recorded'\n",
        "dob_df['certification_status'] = dob_df['certification_status'].replace(np.nan, 'UNKNOWN')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taHjKRJ5nR05"
      },
      "source": [
        "#It looks like the 1 \"Cured/In-Vio\" variable is due to error in data collection\n",
        "#\"Cured In violation\" should be under the hearing status caolumn.\n",
        "#We will drop this one variable.\n",
        "#dob_df = dob_df.loc[dob_df['certification_status'] != \"CURED/IN-VIO\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxn367pLncO1"
      },
      "source": [
        "dob_df.certification_status.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWqa42Dhnj-e"
      },
      "source": [
        "#reset the index for good practice when dropping\n",
        "dob_df = dob_df.reset_index(drop=True)\n",
        "#get the shape of our new dataset\n",
        "dob_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Bka86p8yh3"
      },
      "source": [
        "This can be encoded and engineered to show something of value. Possible NLP techniques here as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aL9d8KPucC2y"
      },
      "source": [
        "#encode text using category\n",
        "dob_df[\"certification_status_cat\"] = lbe.fit_transform(dob_df[\"certification_status\"])\n",
        "dob_df.certification_status_cat.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbX1yCyihA4_"
      },
      "source": [
        "### New Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxqA-gVEUZXu"
      },
      "source": [
        "#create variable for percentage paid of penalty imposed for resolved violations\n",
        "dob_df['percentage_paid'] = round(((dob_df['amount_paid']+1)/(dob_df['penalty_imposed']+1)*100),2)\n",
        "dob_df.percentage_paid.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTFJcb49SEVh"
      },
      "source": [
        "sns.set_style('whitegrid')\n",
        "ax = sns.distplot(dob_df.percentage_paid, bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qlwy_ng_NWmM"
      },
      "source": [
        "## Creating our target variable.\n",
        "Below you can see that amount paid for any violation hover around zero values. \n",
        "\n",
        "This may be caused by the significant amount of violations that have 0 penalty imposed and the negative values in both balance due and amount paid. These values are effectivley outliers with explanitory value.\n",
        "\n",
        "These gross outliers are explained by defaulted violations. A defaulted violation must be paid in order to reopen a case with the city, resulting in a negative balance which the city owes the respondent. Additionally a defaulted violation results in contrastly higher penalty amounts which must be paid.\n",
        "\n",
        "We can effectivley address the class imbalance by creating a descrete variable which takes all of these factors into account.\n",
        "\n",
        "Thus, the features in the data set will hopefully predict if a violation will be paid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqp8KDuYNi3N"
      },
      "source": [
        "sns.set_style('whitegrid')\n",
        "ax = sns.distplot(dob_df.amount_paid, bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge4GEUvhhFUl"
      },
      "source": [
        "#create a variable that shows if the respondent paid anything\n",
        "dob_df[\"paid\"] = dob_df[\"amount_paid\"]\n",
        "dob_df.paid.describe()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-fXFB_kNwOQ"
      },
      "source": [
        "dob_df[\"paid\"] = np.where(((dob_df[\"paid\"]>0) & (dob_df[\"penalty_imposed\"]>0) ),1,0)\n",
        "dob_df.paid.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk4GwH_MOr8y"
      },
      "source": [
        "sns.set_style('whitegrid')\n",
        "ax = sns.distplot(dob_df.paid, bins=30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_UqIWEdQFx3"
      },
      "source": [
        "ax = sns.barplot(y=\"hearing_status\", x=\"amount_paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zghwSQJRrEX"
      },
      "source": [
        "ax = sns.barplot(y=\"hearing_status\", x=\"balance_due\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92f7IuV-Rtwk"
      },
      "source": [
        "ax = sns.barplot(y=\"hearing_status\", x=\"penalty_imposed\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKpkXoeMR9B3"
      },
      "source": [
        "ax = sns.barplot(y=\"hearing_status\", x=\"paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVDDiBkTSLJ8"
      },
      "source": [
        "ax = sns.barplot(x=\"severity\", y=\"paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j32_Ku9BSPH4"
      },
      "source": [
        "ax = sns.barplot(y=\"paid\", x=\"boro\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWC7-ITwSfyN"
      },
      "source": [
        "ax = sns.barplot(x=\"aggravated_level\", y=\"paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BywxpIMhSpA9"
      },
      "source": [
        "ax = sns.barplot(y=\"violation_type\", x=\"paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I26OSP0Gd0qq"
      },
      "source": [
        "ax = sns.barplot(y=\"certification_status\", x=\"paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPlSbpeLhKOA"
      },
      "source": [
        "___\n",
        "## Visualize and Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2cJE7A2cocZ"
      },
      "source": [
        "#look at pairplot to see distributions of most numeric variables\n",
        "X = dob_df[[\"boro\", \"penalty_imposed\", \"percentage_paid\", \"balance_due\",\"amount_paid\", \"paid\"]]\n",
        "sns.pairplot(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvnPQL_lj_Ip"
      },
      "source": [
        "#look at pairplot to see distributions of most numeric variables\n",
        "X = dob_df[[ \"penalty_imposed\", \"percentage_paid\", \"balance_due\",\"amount_paid\"]]\n",
        "sns.pairplot(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OPBax9TLkZq"
      },
      "source": [
        "#look at pairplot to see distributions of most numeric variables\n",
        "X = dob_df[[ \"penalty_imposed\", \"balance_due\",\"amount_paid\"]]\n",
        "sns.pairplot(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsye3iAchJ_u"
      },
      "source": [
        "#create correlation matrix to review possible multicoliniarity\n",
        "X = dob_df.drop([\"ecb_violation_status\", \"hearing_date\", \"hearing_time\", \"violation_type\", \n",
        "                 \"violation_description\", \"hearing_status\", \"certification_status\", \"severity\", \n",
        "                 \"aggravated_level\", \"paid\"], axis=1)\n",
        "X_corr = X.corr()\n",
        "\n",
        "sns.set_context('paper')\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(X_corr, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYU7w6-uq-uZ"
      },
      "source": [
        "#add constant and check vif for X\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "X_sm = sm.add_constant(X)\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF_factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "vif[\"features\"] = X.columns\n",
        "vif.round(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSgJfA6ihiUi"
      },
      "source": [
        "This VIF looks pretty good, will drop the one variable over 10 from this model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0K2tGt9sPjH"
      },
      "source": [
        "#second matrix\n",
        "X = X.drop(columns=[\"hearing_time_morning\"])\n",
        "X_corr = X.corr()\n",
        "\n",
        "sns.set_context('paper')\n",
        "plt.figure(figsize=(10,10))\n",
        "sns.heatmap(X_corr, annot=True)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G03YH50asZAy"
      },
      "source": [
        "#check vif again\n",
        "X_sm = sm.add_constant(X)\n",
        "\n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF_factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "vif[\"features\"] = X.columns\n",
        "vif.round(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koaueD8RY3iU"
      },
      "source": [
        "___\n",
        "## NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCRf_RdDhT5z"
      },
      "source": [
        "With the number of datapoints, we run into some memory limitations unless we take a subset sample of the data.  We will train our models on 100K of 1370365.  A seperate project with additional computational resources would be a great comparison to utalize the full dataset and hopefully improve performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG0bz31U3AAg"
      },
      "source": [
        "#create dataset dropping duplicates values and unimportant features\n",
        "dob = dob_df.drop([\"ecb_violation_status\",\"hearing_date\", \"hearing_time\", \n",
        "                   \"hearing_status\", \"certification_status\", \"hearing_time_morning\",\n",
        "                   \"severity\", \"aggravated_level\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6KDOyDXwY7J"
      },
      "source": [
        "dob_sample = dob.sample(n=100000, replace=False, random_state=42)\n",
        "dob_sample.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4imEFqL2jH-"
      },
      "source": [
        "dob_sample.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEECeyUojQcs"
      },
      "source": [
        "Before building our classifier with text, we need to clean the data as follows:\n",
        "\n",
        "  * Making all characters lowercase, and removing punctuation\n",
        "\n",
        "  * Removing the stopwords\n",
        "\n",
        "  * Normalizing the words (aka lemmatization or stemming)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGQ67wy037GZ"
      },
      "source": [
        "#### Text Preprocessing- Cleaning the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1orRHsp7e2p"
      },
      "source": [
        "dob_sample['clean_description'] = dob_sample['violation_description'].str.strip().str.lower().str.replace(\n",
        "    '(', ' ').str.replace(')', ' ').str.replace('/', '').str.replace(\",\", \" \").str.replace(\n",
        "        \":\",\"\").str.replace(\"@\", \"\").str.replace(\"&\", \"\").str.replace(\"-\", \"\").str.replace(\"   \",\" \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCxYB1u6uOpw"
      },
      "source": [
        "dob_sample['clean_description'] = dob_sample['clean_description'].str.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgDvQSSa9adg"
      },
      "source": [
        "#### Removing stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd88emg-8tJG"
      },
      "source": [
        "# Removing Stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Here is a list of the stopwords identified by NLTK.\n",
        "\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "510lJpc_5cZR"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words(\"english\")                \n",
        "\n",
        "dob_sample['clean_description'] = dob_sample['clean_description'].apply(\n",
        "    lambda x: [word for word in x if word not in stop])\n",
        "#dob_sample['clean_type'] = dob_sample['clean_type'].apply(lambda x: [word for word in x if word not in stop])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4lyUGQrW9un"
      },
      "source": [
        "dob_sample.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WInbCQfa9eyd"
      },
      "source": [
        "#### Lemmaization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ujkI1088ta"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# lemmatizing\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "lemma = nltk.WordNetLemmatizer()\n",
        "\n",
        "\n",
        "dob_sample['clean_description'] = dob_sample['clean_description'].apply(\n",
        "    lambda violation: [lemma.lemmatize(word) for word in violation])\n",
        "#dob_sample['clean_type'] = dob_sample['clean_type'].apply(\n",
        " #   lambda violation: [lemma.lemmatize(word) for word in violation])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utcx9ed2Z0a9"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(background_color=\"orange\").generate(\" \".join(dob_sample[\"clean_description\"].astype('unicode').values))\n",
        "plt.figure(figsize=(15,10))\n",
        "# Display the generated image:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1x4ByHy_WPY"
      },
      "source": [
        "### Feature Extraction Diminsionality Reduction and Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilDBThIxk5vi"
      },
      "source": [
        "#extract features\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "X = dob_sample[\"clean_description\"].astype('unicode').values\n",
        "vectorizer = TfidfVectorizer(lowercase=False)\n",
        "X_text = vectorizer.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GZzYnQ8xX-E"
      },
      "source": [
        "X_text.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n50yZ1KTBKLG"
      },
      "source": [
        "We will reduce the size using dimensionality reduction techniques before splitting our data into training and test sets for our classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4BHG3j93cfn"
      },
      "source": [
        "#Dimensionality reduction\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "#Our SVD data reducer.  We are going to reduce the feature space from 130640 to 600.\n",
        "svd= TruncatedSVD(600)\n",
        "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
        "\n",
        "X_text_processed = lsa.fit_transform(X_text)\n",
        "\n",
        "variance_explained=svd.explained_variance_ratio_\n",
        "total_variance = variance_explained.sum()\n",
        "print(\"Percent variance captured by all components:\",total_variance*100)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IxfnCG7yMhH"
      },
      "source": [
        "#create data fram\n",
        "tfidf_df = pd.DataFrame(X_text_processed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8gJrVrOPI50"
      },
      "source": [
        "tfidf_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbzTnA6__JWZ"
      },
      "source": [
        "#set index of both the new tftdf/svd/lsa datafram and dob_sample equal\n",
        "dob_sample.index=tfidf_df.index\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrNO_2WgzTHe"
      },
      "source": [
        "#create a new dataframe to include vectorized demsion reduced data and cleaned numeric data from dataset\n",
        "dob_clean = pd.concat([tfidf_df, dob_sample[[\"boro\", \"severity_cat\", \"aggravated_level_cat\",\"violation_status\", \n",
        "                                             \"hearing_status_cat\", \"certification_status_cat\", \"penalty_imposed\",\n",
        "                                             \"paid\", \"percentage_paid\"]]], axis=1)\n",
        "\n",
        "# so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
        "dob_clean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "reFPu9_muAQb"
      },
      "source": [
        "## Feature selected after Model implemetation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_OdtZ_vtm_Q"
      },
      "source": [
        "#create a new dataframe to include vectorized demsion reduced data and cleaned numeric data from dataset\n",
        "dob_clean2 = pd.concat([tfidf_df, dob_sample[[\"boro\", \"severity_cat\", \"aggravated_level_cat\",\"violation_status\", \n",
        "                                             \"hearing_status_cat\", \"certification_status_cat\", \n",
        "                                             \"paid\"]]], axis=1)\n",
        "\n",
        "# so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
        "dob_clean.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cUZmogR31pQ"
      },
      "source": [
        "#define target and features\n",
        "y = dob_clean[\"paid\"]\n",
        "X = dob_clean.drop(\"paid\", axis=1)\n",
        "X_2 = dob_clean2.drop(\"paid\", axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN6H4sXh30wg"
      },
      "source": [
        "# split data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#split second training set\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_2, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOlfaBSiBxIk"
      },
      "source": [
        "## Model Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AltwuX7wB4b_"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvoGO5ufZ7sy"
      },
      "source": [
        "#### Model 1\n",
        "Logistic Regression with gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4cuvg9SZ7Re"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_cv_params = {\"C\": np.logspace(-1,1,10), \"max_iter\": [1000, 5000, 10000]}\n",
        "clf_lr = LogisticRegression()\n",
        "clf_lr_optimized = GridSearchCV(clf_lr, lr_cv_params, cv=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEkOh6LNaDAw"
      },
      "source": [
        "#clf_lr_optimized.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mnEpS7xaGeI"
      },
      "source": [
        "# Print parameters for best-performing grid\n",
        "#print('Best params: %s' % clf_lr_optimized.best_params_)\n",
        "# Best training data accuracy\n",
        "#print('Best GridSearchCV training accuracy: %.3f' % clf_lr_optimized.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-rs5oKnaVNK"
      },
      "source": [
        "# Train model on full training split w/ best params determined by GridSearchCV \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf_lr = LogisticRegression(C=5.994842503189409, max_iter=1000)\n",
        "clf_lr_optimized = clf_lr.fit(X_train, y_train)\n",
        "# Make predictions w/ best params\n",
        "y_pred_test = clf_lr_optimized.predict(X_test)\n",
        "y_pred_train = clf_lr_optimized.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-tsmZhkabOG"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Test data accuracy of model with best params\n",
        "print('Training set accuracy score for Logistic Regression Classifier w/ best params: %.3f ' \n",
        "      % accuracy_score(y_train, y_pred_train))\n",
        "print('Test set accuracy score for Logistic Regression Classifier w/ best params: %.3f ' \n",
        "      % accuracy_score(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99MN8gQ0ac9t"
      },
      "source": [
        "# Set up classification report and confusion matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(metrics.classification_report(y_test, y_pred_test, target_names = [\"Unpaid\", \"Paid\"]))\n",
        "clf_lr_cnf = confusion_matrix(y_test, y_pred_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMDNOco_akl8"
      },
      "source": [
        "# plot confusion matrix without and with normalization\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "class_names = [\"Unpaid\", \"Paid\"]\n",
        "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
        "                  (\"Normalized confusion matrix\", 'true')]\n",
        "for title, normalize in titles_options:\n",
        "    disp = plot_confusion_matrix(clf_lr_optimized, X_test, y_test,\n",
        "                                 display_labels=class_names,\n",
        "                                 cmap=plt.cm.PuBuGn,\n",
        "                                 normalize=normalize)\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Je2aubYSGgyM"
      },
      "source": [
        "# visualize confusion matrix using mlxtend \n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=clf_lr_cnf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svJPlKfKWejy"
      },
      "source": [
        "print(clf_lr_optimized.predict_proba(X_test).mean())\n",
        "\n",
        "print(clf_lr_optimized.predict_proba(X_train).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKDs7xoOucg0"
      },
      "source": [
        "#### Model 2\n",
        "Logistic Regression with gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YVqCvuQucg7"
      },
      "source": [
        "# Train 2nd model on full training split w/ best params determined by GridSearchCV \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "clf_lr2 = LogisticRegression(C=5.994842503189409, max_iter=1000)\n",
        "clf_lr_optimized2 = clf_lr.fit(X_train2, y_train2)\n",
        "# Make predictions w/ best params\n",
        "y_pred_test2 = clf_lr_optimized.predict(X_test2)\n",
        "y_pred_train2 = clf_lr_optimized.predict(X_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hDIP_n6ucg-"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Test data accuracy of model with best params\n",
        "print('Training set accuracy score for Logistic Regression Classifier w/ best params: %.3f ' \n",
        "      % accuracy_score(y_train2, y_pred_train2))\n",
        "print('Test set accuracy score for Logistic Regression Classifier w/ best params: %.3f ' \n",
        "      % accuracy_score(y_test2, y_pred_test2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3CmcwQyuchA"
      },
      "source": [
        "# Set up classification report and confusion matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print(metrics.classification_report(y_test2, y_pred_test2, target_names = [\"Unpaid\", \"Paid\"]))\n",
        "clf_lr_cnf2 = confusion_matrix(y_test2, y_pred_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZyeP-xHuchF"
      },
      "source": [
        "# visualize confusion matrix using mlxtend \n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=clf_lr_cnf2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IcKoFDLuchH"
      },
      "source": [
        "print(clf_lr_optimized2.predict_proba(X_test2).mean())\n",
        "\n",
        "print(clf_lr_optimized2.predict_proba(X_train2).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2YZz7DlC5D4"
      },
      "source": [
        "### K-Nearest Neighbors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U3_96jEC9_V"
      },
      "source": [
        "#### Model 1\n",
        "\n",
        "KNN with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSwY1J7D4eHV"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_cv_params = {\"n_neighbors\": [3,5,10], \"metric\": ['euclidean', 'manhattan']}\n",
        "clf_knn = KNeighborsClassifier()\n",
        "clf_knn_optimized = GridSearchCV(clf_knn, knn_cv_params, cv=5, n_jobs = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YfwCM0TH7Vz"
      },
      "source": [
        "#clf_knn_optimized.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlu4gOcMH7ai"
      },
      "source": [
        "# Print per-grid model performance\n",
        "#print(\"Parameters for KNN Classifier Grids: {}\".format(clf_knn_optimized.cv_results_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiWmItGf9TZz"
      },
      "source": [
        "# Print parameters for best-performing grid\n",
        "#print('Best params: %s' % clf_knn_optimized.best_params_)\n",
        "# Best training data accuracy\n",
        "#print('Best GridSearchCV training accuracy: %.3f' % clf_knn_optimized.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdVHQyTg-ab8"
      },
      "source": [
        "# Train model on full training split w/ best params determined by GridSearchCV \n",
        "clf_knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
        "clf_knn_optimized_final = clf_knn.fit(X_train, y_train)\n",
        "# Make predictions w/ best params\n",
        "y_pred_test = clf_knn_optimized_final.predict(X_test)\n",
        "y_pred_train = clf_knn_optimized_final.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7ETegJCDqYJ"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Test data accuracy of model with best params\n",
        "print('Test set accuracy score for KNN Classifier w/ best params: %.3f ' % accuracy_score(y_train, y_pred_train))\n",
        "print('Test set accuracy score for KNN Classifier w/ best params: %.3f ' % accuracy_score(y_test, y_pred_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtHOSLbAEQLh"
      },
      "source": [
        "# Set up classification report and confusion matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "clf_knn_pred = clf_knn_optimized_final.predict(X_test)\n",
        "print(metrics.classification_report(y_test, clf_knn_pred, target_names = [\"Unpaid\", \"Paid\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_CwCYJdEQLj"
      },
      "source": [
        "clf_knn_cnf = confusion_matrix(y_test, clf_knn_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "67lKpPutEQLm"
      },
      "source": [
        "# visualize confusion matrix using mlxtend \n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=clf_knn_cnf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8ImcFOHW8a8"
      },
      "source": [
        "print(\"Testing Probability: \", clf_knn_optimized_final.predict_proba(X_test).mean())\n",
        "print(\"Training Probability: \",clf_knn_optimized_final.predict_proba(X_train).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceyJnucVu6Dy"
      },
      "source": [
        "#### Model 2\n",
        "\n",
        "KNN with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmEXkADOu6D8"
      },
      "source": [
        "# Train model on full training split w/ best params determined by GridSearchCV \n",
        "clf_knn2 = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
        "clf_knn_optimized_2 = clf_knn2.fit(X_train2, y_train2)\n",
        "# Make predictions w/ best params\n",
        "y_pred_test2 = clf_knn_optimized_2.predict(X_test2)\n",
        "y_pred_train2 = clf_knn_optimized_2.predict(X_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT8660IVu6D_"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Test data accuracy of model with best params\n",
        "print('Test set accuracy score for KNN Classifier w/ best params: %.3f ' % accuracy_score(y_train2, y_pred_train2))\n",
        "print('Test set accuracy score for KNN Classifier w/ best params: %.3f ' % accuracy_score(y_test2, y_pred_test2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDSafZHbu6EB"
      },
      "source": [
        "# Set up classification report and confusion matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "clf_knn_pred2 = clf_knn_optimized_2.predict(X_test2)\n",
        "print(metrics.classification_report(y_test2, clf_knn_pred2, target_names = [\"Unpaid\", \"Paid\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45TJ0bYzu6ED"
      },
      "source": [
        "clf_knn_cnf2 = confusion_matrix(y_test2, clf_knn_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "VAWz1ZoCu6EF"
      },
      "source": [
        "# visualize confusion matrix using mlxtend \n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=clf_knn_cnf2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVBUqlDtu6EG"
      },
      "source": [
        "#print(\"Testing Probability: \", clf_knn_optimized_2.predict_proba(X_test2).mean())\n",
        "#print(\"Training Probability: \",clf_knn_optimized_2.predict_proba(X_train2).mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZY5E__-4G-R"
      },
      "source": [
        "### XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI-8j4iGDVyq"
      },
      "source": [
        "#### Model 1\n",
        "XGBoost with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6BMUSQY4eHc"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "# Optimize for accuracy since that is the metric we used earlier to score models\n",
        "# Explore max_depth and min_child_weight via GridSearchCV\n",
        "# Reducing subsample and colsample to 0.6 to avoid RAM overrun\n",
        "\n",
        "xgb_cv_params = {'max_depth': [3,5,7], 'min_child_weight': [1,3,5]}\n",
        "xgb_ind_params = {'learning_rate': 0.1, 'n_estimators': 100, 'seed':0, 'subsample': 0.6, 'colsample_bytree': 0.6, \n",
        "             'objective': 'multi:softprob', 'num_class': 5}\n",
        "clf_xgb_optimized = GridSearchCV(XGBClassifier(**xgb_ind_params),\n",
        "                            xgb_cv_params, \n",
        "                            scoring = 'accuracy', cv = 5, n_jobs = -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba38_0Rp7kQm"
      },
      "source": [
        "#clf_xgb_optimized.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "lrhctL5y7ujl"
      },
      "source": [
        "# Check per-grid model results\n",
        "#print(\"Accuracy for XGBoost Classifier Grids: {}\".format(clf_xgb_optimized.cv_results_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lKjZ4O5GMjW"
      },
      "source": [
        "# Print parameters for best-performing grid\n",
        "#print('Best params: %s' % clf_xgb_optimized.best_params_)\n",
        "# Best training data accuracy\n",
        "#print('Best GridSearchCV training accuracy: %.3f' % clf_xgb_optimized.best_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yzr-W7PyGMjZ"
      },
      "source": [
        "# Train model on full training split w/ best params determined by GridSearchCV \n",
        "clf_xgb = XGBClassifier(max_depth= 5, min_child_weight =3 )\n",
        "clf_xgb_optimized = clf_xgb.fit(X_train, y_train)\n",
        "# Make predictions w/ best params\n",
        "y_pred_test = clf_xgb_optimized.predict(X_test)\n",
        "y_pred_train = clf_xgb_optimized.predict(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0faVc3mGMjb"
      },
      "source": [
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Test data accuracy of model with best params\n",
        "print('Test set accuracy score for XGBoost Classifier w/ best params: %.3f ' % accuracy_score(y_test, y_pred_test))\n",
        "print('Train set accuracy score for XGBoost Classifier w/ best params: %.3f ' % accuracy_score(y_train, y_pred_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "4ZP21O-QzxVz"
      },
      "source": [
        "# Check overall model 'accuracy'\n",
        "print(\"Accuracy for XGBoost Classifier on test set: {}\".format(clf_xgb_optimized.score(X_test, y_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3oGIcEPzxV4"
      },
      "source": [
        "# Set up classification report and confusion matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "clf_xgb_pred = clf_xgb_optimized.predict(X_test)\n",
        "print(metrics.classification_report(y_test, clf_xgb_pred, target_names = [\"Unpaid\", \"Paid\"]))\n",
        "clf_xgb_cnf = confusion_matrix(y_test, clf_xgb_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "dLm8FZfvzxV_"
      },
      "source": [
        "# visualize confusion matrix using mlxtend \n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=clf_xgb_cnf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rKyu1R7q7A2"
      },
      "source": [
        "\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(clf_xgb_optimized.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fnseg3mAvbEY"
      },
      "source": [
        "#### Model 2\n",
        "XGBoost with GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcE0r_TOvbEg"
      },
      "source": [
        "# Train model on full training split w/ best params determined by GridSearchCV \n",
        "clf_xgb2 = XGBClassifier(max_depth= 5, min_child_weight =3 )\n",
        "clf_xgb_optimized2 = clf_xgb2.fit(X_train2, y_train2)\n",
        "# Make predictions w/ best params\n",
        "y_pred_test2 = clf_xgb_optimized2.predict(X_test2)\n",
        "y_pred_train2 = clf_xgb_optimized2.predict(X_train2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I0K1Qa8vbEi"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "# Test data accuracy of model with best params\n",
        "print('Test set accuracy score for XGBoost Classifier w/ best params: %.3f ' % accuracy_score(y_test2, y_pred_test2))\n",
        "print('Train set accuracy score for XGBoost Classifier w/ best params: %.3f ' % accuracy_score(y_train2, y_pred_train2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "XmbxUPQLvbEk"
      },
      "source": [
        "# Check overall model 'accuracy'\n",
        "print(\"Accuracy for XGBoost Classifier on test set: {}\".format(clf_xgb_optimized2.score(X_test2, y_test2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZNO6-MkvbEl"
      },
      "source": [
        "# Set up classification report and confusion matrix\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "clf_xgb_pred2 = clf_xgb_optimized2.predict(X_test2)\n",
        "print(metrics.classification_report(y_test2, clf_xgb_pred2, target_names = [\"Unpaid\", \"Paid\"]))\n",
        "clf_xgb_cnf2 = confusion_matrix(y_test2, clf_xgb_pred2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "mFnILa3DvbEn"
      },
      "source": [
        "# visualize confusion matrix using mlxtend \n",
        "from mlxtend.evaluate import confusion_matrix\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "\n",
        "fig, ax = plot_confusion_matrix(conf_mat=clf_xgb_cnf2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVgtRm35vbEp"
      },
      "source": [
        "\n",
        "#plot graph of feature importances for better visualization\n",
        "feat_importances = pd.Series(clf_xgb_optimized2.feature_importances_, index=X_2.columns)\n",
        "feat_importances.nlargest(10).plot(kind='barh')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDDVa_Zo-wO3"
      },
      "source": [
        "___\n",
        "## Dummy Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tfJZ5LY7l01"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "dum = DummyClassifier(strategy='most_frequent', random_state=42)\n",
        "clf_dum = dum.fit(X_train, y_train)\n",
        "y_pred = clf_dum.predict(y_test)\n",
        "print('accuracy score for Dummy Classifier: %.3f ' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jocIyk5z8H_N"
      },
      "source": [
        "dummy_report = classification_report(y_test, dum.predict(X_test), target_names=['Unpaid', 'Paid'])\n",
        "print(dummy_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2chBbpUAkY30"
      },
      "source": [
        "___\n",
        "## Conclusion\n",
        "The results from our models clearly predict with a lot of confidence, both our training and test sets, if a violation will be paid. \n",
        "\n",
        "\n",
        "\n",
        "> Our baseline dummy classifier with a 54% pales in comparison to the classifiers we built. Although they all perform well, the XGBoost classifier (although it took the longest to run) with 99% accuracy is clearly our best performing model. As a classifier it performs best using parallel processing and without over fitting. **Clear winner!**\n",
        "\n",
        "\n",
        "\n",
        "This could be a useful tool for a NYC DOB built system/interface to help collect any outstanding fines. Review the current process and send reminders annually or quarterly to the respondent of record to address, ultimatley avoiding default penalties. \n",
        "\n",
        "Defaulted penalties rarley get paid, prohibit building owners from certain city permitting and are ineffective in long term goals of promoting saftey.\n",
        "\n",
        "Perhaps there is room to tie this into application processes for building permits. Taking preventative measures in addressing outstanding violations before approval for permits.\n",
        "\n",
        "I realize my model was not as large as the original dataset. It would be interesting to test this on the full data set given additional computational resources. \n",
        "\n",
        "As this model is connected to the api, updated daily,  the source will mostly be up to date to continue to include these records in our model moving forward. (It was interesting that some methods I used to clean the data were irrelevant after re-running my notebook. They must be cleaning up some of the data after the building colapse in Brooklyn last week.)\n",
        "\n",
        "My initial goal for this project was to create a type of chat bot asking the user for all information regarding the violation, whether that was the building owner or DOB inspector. The response would be generated based on the collected information from the user and respond with the potential payment and or hearing details. This would in turn avoid defaulted violations which collect interest and are the highest balances acrued to the city. However with limited computational resources the interactive experience will have to wait.\n",
        "\n",
        "At the same time, this is the start to a formalized system that the DOB could utalize to save money, review cand address current proceses and connect with the city's building owners to promote saftey citywide."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXoK-4xhDJ4O"
      },
      "source": [
        "## Additional Visuals"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nVWzD8U4OWa"
      },
      "source": [
        "ax = sns.barplot(y=\"ecb_violation_status\", x=\"penalty_imposed\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTpAjNknuj4o"
      },
      "source": [
        "ax = sns.barplot(x=\"boro\", y=\"amount_paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMbMx50hJz31"
      },
      "source": [
        "ax = sns.barplot(x=\"boro\", y=\"balance_due\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_llFZrLoJ3gI"
      },
      "source": [
        "ax = sns.barplot(x=\"boro\", y=\"penalty_imposed\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oS9lqTEXKHqo"
      },
      "source": [
        "ax = sns.barplot(y=\"hearing_status\", x=\"balance_due\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI3XTf0iKjgp"
      },
      "source": [
        "ax = sns.barplot(y=\"hearing_status\", x=\"amount_paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4kQreQMKndA"
      },
      "source": [
        "ax = sns.barplot(y=\"hearing_status\", x=\"penalty_imposed\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akzAvcolMXsP"
      },
      "source": [
        "ax = sns.barplot(y=\"violation_type\", x=\"balance_due\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qbha2QsMfUJ"
      },
      "source": [
        "ax = sns.barplot(y=\"violation_type\", x=\"amount_paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O70snNptNOWe"
      },
      "source": [
        "ax = sns.barplot(y=\"violation_type\", x=\"penalty_imposed\", data=dob_df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ue1UoreIxd7z"
      },
      "source": [
        "ax = sns.barplot(y=\"violation_type\", x=\"penalty_imposed\", data=dob_df.loc[dob_df['violation_type']!= \"Non-Hazardous\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBFS1garZ6wk"
      },
      "source": [
        "ax = sns.barplot(y=\"violation_type\", x=\"amount_paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3tFydy0aBlQ"
      },
      "source": [
        "ax = sns.barplot(y=\"violation_type\", x=\"amount_paid\", data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPHVt36UNbgs"
      },
      "source": [
        "sns.scatterplot(y=\"amount_paid\", x=\"penalty_imposed\", hue='paid', size='ecb_violation_status', data=dob_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOmgtjo_awcO"
      },
      "source": [
        "g = sns.PairGrid(dob, vars=['penalty_imposed', 'amount_paid', 'balance_due'], size=2.5)\n",
        "g = g.map_diag(plt.hist)\n",
        "g = g.map_offdiag(plt.scatter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzmU8qUBbSwY"
      },
      "source": [
        "g = sns.PairGrid(dob_df, vars=['penalty_imposed', 'amount_paid', 'balance_due'], hue=\"ecb_violation_status\", size=2.5)\n",
        "g = g.map_diag(plt.hist)\n",
        "g = g.map_offdiag(plt.scatter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DmjlwrZGB6h"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# Generate a word cloud image\n",
        "wordcloud = WordCloud(background_color=\"orange\").generate(\" \".join(dob_df[\"violation_type\"].unique()))\n",
        "plt.figure(figsize=(15,10))\n",
        "# Display the generated image:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLlaVhLXHA17"
      },
      "source": [
        "cat_columns = dob_df[[\"ecb_violation_status\", \"certification_status\",\"boro\",\"severity\", \"aggravated_level\", \"hearing_status\"]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vfI6mbfGZ6F"
      },
      "source": [
        "plt.figure(figsize=(30,50))\n",
        "\n",
        "for index, column in enumerate(cat_columns):\n",
        "  plt.subplot(8, 2, index+1)\n",
        "  plt.bar(dob_df.groupby(column)[\"penalty_imposed\"].mean().index, \n",
        "          dob_df.groupby(column)[\"penalty_imposed\"].mean())\n",
        "  plt.title(\"Average Penalty Imposed wrt. {}\".format(column))\n",
        "  plt.ylabel(\"Average Penalty Imposed\")\n",
        "  plt.xlabel(column)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQDtdukYHqY_"
      },
      "source": [
        "plt.figure(figsize=(20,40))\n",
        "\n",
        "for index, column in enumerate(cat_columns):\n",
        "  plt.subplot(8, 2, index+1)\n",
        "  plt.bar(dob_df.groupby(column)[\"amount_paid\"].mean().index, \n",
        "          dob_df.groupby(column)[\"amount_paid\"].mean())\n",
        "  plt.title(\"Paid Violations wrt. {}\".format(column))\n",
        "  plt.ylabel(\"Paid Violations\")\n",
        "  plt.xlabel(column)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJIZ-eMeRgtJ"
      },
      "source": [
        "\n",
        "sns.lmplot(x=\"penalty_imposed\", y=\"balance_due\", hue= \"violation_type\",\n",
        "           col=\"boro\", row=\"paid\", data=dob_df);\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OJY-JUGgsIw"
      },
      "source": [
        "dob_df.violation_description[:1].values"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}